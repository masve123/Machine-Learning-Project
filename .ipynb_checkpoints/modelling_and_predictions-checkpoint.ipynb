{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89a897b",
   "metadata": {},
   "source": [
    "# INF161: Data Science: Course Project\n",
    "### *Predicting how many people cycle over Nygårdsbroen at a given time*\n",
    "\n",
    "> #### by [Mathias Svendsen]\n",
    ">-------------------------------------------\n",
    "> *Autumn 2022* \n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "<a id=\"top\"></a> \n",
    "\n",
    "<h2> Part 2: Modelling and Predictions</h2>\n",
    "    \n",
    "#### *Notebook Index:*\n",
    "1. [**Exploratory Data Analysis & Feature Engineering**](#analysis) <br>\n",
    "    1.1 [*Splitting the dataset*](#analysis) <br>\n",
    "    1.2 [*Exploring the concatenated traffic and weather data*](#traffic_data) <br>\n",
    "    1.3 [*Further analysis with regards to the scaling of given data*](#scaling) <br>\n",
    "    1.4 [*Correlation analysis*](#Correlation-analysis) <br>\n",
    "    </div>\n",
    "2. [**Modelling: First Iteration**](#feature-selection) <br>\n",
    "    2.1 [*Scaling the data*](#scaling) <br>\n",
    "    2.2 [*Linear Regression Models*](#linear_regression) <br>\n",
    "    2.3 [*The Polynomial Model*](#polynomial_model) <br>\n",
    "    2.4 [*K Nearest Neighbour*](#k_nearest_neighbour) <br>\n",
    "    2.5 [*The Decision Tree Model](#decision_tree) <br>\n",
    "    2.6 [*The Multi Layer Perceptron*](#mlp) <br>\n",
    "3. [**Feature Engineering**](#feature-engineering) <br>\n",
    "    3.1 [*Something...*](#comment) <br>\n",
    "    3.2 [*Something...*](#comment) <br>\n",
    "    3.3 [*Something...*](#comment) <br>\n",
    "    3.4 [*Something...*](#comment) <br>\n",
    "4. [**Final test and evaluation**](#saving) <br>\n",
    "5. [**Actual Prediction**](#Prediction-model) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f93e2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing notebook dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn import utils\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer, RobustScaler, StandardScaler, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.multioutput import RegressorChain, MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from math import sqrt, ceil\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# Setting options\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Setting random state for all estimators and functions that use randomization\n",
    "random_state = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e124a0",
   "metadata": {},
   "source": [
    "## <a id=\"analysis\"></a>1) Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9f4c7",
   "metadata": {},
   "source": [
    "This section will consist of both modelling and predictions to further estimate how many people cycle over the bridge at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19272774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing prepared data in .csv format\n",
    "\n",
    "train_data_df = pd.read_csv('train_data.csv')\n",
    "val_data_df   = pd.read_csv('val_data.csv')\n",
    "test_data_df  = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc697a",
   "metadata": {},
   "source": [
    "By running our imported dataframe we can see that some metadata has changed from Preparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfd6d2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>Volum</th>\n",
       "      <th>Lufttemperatur</th>\n",
       "      <th>Vindstyrke</th>\n",
       "      <th>Solskinstid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-16 16:00:00</td>\n",
       "      <td>107</td>\n",
       "      <td>13.733333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>48.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-16 17:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-16 18:00:00</td>\n",
       "      <td>57</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-16 19:00:00</td>\n",
       "      <td>49</td>\n",
       "      <td>12.683333</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-16 20:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>2.483333</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DT  Volum  Lufttemperatur  Vindstyrke  Solskinstid\n",
       "0  2015-07-16 16:00:00    107       13.733333    4.333333         48.7\n",
       "1  2015-07-16 17:00:00     84       13.866667    3.933333         60.0\n",
       "2  2015-07-16 18:00:00     57       13.216667    4.233333         60.0\n",
       "3  2015-07-16 19:00:00     49       12.683333    2.950000         60.0\n",
       "4  2015-07-16 20:00:00     45       12.066667    2.483333         36.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a0ffa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DT                 object\n",
       "Volum               int64\n",
       "Lufttemperatur    float64\n",
       "Vindstyrke        float64\n",
       "Solskinstid       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df65d43",
   "metadata": {},
   "source": [
    "Now, our datetime index has been reset. It is also of type Object and not datetime, which is not useful for our model. Hence, we update it so that it can be utilized accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64c9d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df['DT'] = pd.to_datetime(train_data_df['DT'])\n",
    "val_data_df['DT'] = pd.to_datetime(val_data_df['DT'])\n",
    "test_data_df['DT'] = pd.to_datetime(test_data_df['DT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a74ae2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DT                False\n",
       "Volum             False\n",
       "Lufttemperatur    False\n",
       "Vindstyrke        False\n",
       "Solskinstid       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any NaN-values before setting the index\n",
    "train_data_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1db2357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DT                False\n",
       "Volum             False\n",
       "Lufttemperatur    False\n",
       "Vindstyrke        False\n",
       "Solskinstid       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db9f4e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DT                False\n",
       "Volum             False\n",
       "Lufttemperatur    False\n",
       "Vindstyrke        False\n",
       "Solskinstid       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebe88f",
   "metadata": {},
   "source": [
    "The data seems to be in order, which is necessary before proceeding to use it as input in our model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b3c3c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>Volum</th>\n",
       "      <th>Lufttemperatur</th>\n",
       "      <th>Vindstyrke</th>\n",
       "      <th>Solskinstid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-16 16:00:00</td>\n",
       "      <td>107</td>\n",
       "      <td>13.733333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>48.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-16 17:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-16 18:00:00</td>\n",
       "      <td>57</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-16 19:00:00</td>\n",
       "      <td>49</td>\n",
       "      <td>12.683333</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-16 20:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>2.483333</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44820</th>\n",
       "      <td>2021-12-31 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44821</th>\n",
       "      <td>2021-12-31 18:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44822</th>\n",
       "      <td>2021-12-31 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>5.616667</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44823</th>\n",
       "      <td>2021-12-31 20:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44824</th>\n",
       "      <td>2021-12-31 22:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3.716667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44825 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DT  Volum  Lufttemperatur  Vindstyrke  Solskinstid\n",
       "0     2015-07-16 16:00:00    107       13.733333    4.333333         48.7\n",
       "1     2015-07-16 17:00:00     84       13.866667    3.933333         60.0\n",
       "2     2015-07-16 18:00:00     57       13.216667    4.233333         60.0\n",
       "3     2015-07-16 19:00:00     49       12.683333    2.950000         60.0\n",
       "4     2015-07-16 20:00:00     45       12.066667    2.483333         36.0\n",
       "...                   ...    ...             ...         ...          ...\n",
       "44820 2021-12-31 17:00:00      4        6.533333    1.250000          0.0\n",
       "44821 2021-12-31 18:00:00      5        6.483333    0.466667          0.0\n",
       "44822 2021-12-31 19:00:00      4        5.616667    2.650000          0.0\n",
       "44823 2021-12-31 20:00:00      2        4.700000    1.916667          0.0\n",
       "44824 2021-12-31 22:00:00      2        3.716667    0.600000          0.0\n",
       "\n",
       "[44825 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442b257",
   "metadata": {},
   "source": [
    "Now it's time to split our dataset into separate variables for the purpose of getting an efficient model.\n",
    "\n",
    "By splitting the data into X and y variables, we can use that data to make our predictions more accurate. In this case, it makes sense to let X represent the weather conditions and y the amount of bikes (volume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36401a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>Volum</th>\n",
       "      <th>Lufttemperatur</th>\n",
       "      <th>Vindstyrke</th>\n",
       "      <th>Solskinstid</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-16 16:00:00</td>\n",
       "      <td>107</td>\n",
       "      <td>13.733333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>48.7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-16 17:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-16 18:00:00</td>\n",
       "      <td>57</td>\n",
       "      <td>13.216667</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-16 19:00:00</td>\n",
       "      <td>49</td>\n",
       "      <td>12.683333</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-16 20:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>2.483333</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44820</th>\n",
       "      <td>2021-12-31 17:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44821</th>\n",
       "      <td>2021-12-31 18:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44822</th>\n",
       "      <td>2021-12-31 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>5.616667</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44823</th>\n",
       "      <td>2021-12-31 20:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44824</th>\n",
       "      <td>2021-12-31 22:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3.716667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44825 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DT  Volum  Lufttemperatur  Vindstyrke  Solskinstid  \\\n",
       "0     2015-07-16 16:00:00    107       13.733333    4.333333         48.7   \n",
       "1     2015-07-16 17:00:00     84       13.866667    3.933333         60.0   \n",
       "2     2015-07-16 18:00:00     57       13.216667    4.233333         60.0   \n",
       "3     2015-07-16 19:00:00     49       12.683333    2.950000         60.0   \n",
       "4     2015-07-16 20:00:00     45       12.066667    2.483333         36.0   \n",
       "...                   ...    ...             ...         ...          ...   \n",
       "44820 2021-12-31 17:00:00      4        6.533333    1.250000          0.0   \n",
       "44821 2021-12-31 18:00:00      5        6.483333    0.466667          0.0   \n",
       "44822 2021-12-31 19:00:00      4        5.616667    2.650000          0.0   \n",
       "44823 2021-12-31 20:00:00      2        4.700000    1.916667          0.0   \n",
       "44824 2021-12-31 22:00:00      2        3.716667    0.600000          0.0   \n",
       "\n",
       "       weekday  \n",
       "0            3  \n",
       "1            3  \n",
       "2            3  \n",
       "3            3  \n",
       "4            3  \n",
       "...        ...  \n",
       "44820        4  \n",
       "44821        4  \n",
       "44822        4  \n",
       "44823        4  \n",
       "44824        4  \n",
       "\n",
       "[44825 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New column representing each day of the week\n",
    "\n",
    "train_data_df['weekday'] = train_data_df['DT'].dt.dayofweek\n",
    "\n",
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cac8d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data and converting to numpy array for further manipulations\n",
    "X_train = train_data_df.drop(['DT', 'Volum'], axis=1).to_numpy() \n",
    "y_train = train_data_df.drop(['DT', 'Lufttemperatur', 'Vindstyrke', 'Solskinstid', 'weekday'], axis=1).to_numpy()\n",
    "\n",
    "X_val = train_data_df.drop(['DT', 'Volum'], axis=1).to_numpy() \n",
    "y_val = train_data_df.drop(['DT', 'Lufttemperatur', 'Vindstyrke', 'Solskinstid','weekday'], axis=1).to_numpy()\n",
    "\n",
    "X_test = train_data_df.drop(['DT', 'Volum'], axis=1).to_numpy() \n",
    "y_test = train_data_df.drop(['DT', 'Lufttemperatur', 'Vindstyrke', 'Solskinstid','weekday'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66bfe7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and validation data. It will be used for the re-training before predicting on test data. \n",
    "X_trainval = np.concatenate([X_train, X_val])\n",
    "y_trainval = np.concatenate([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09823528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fortsett her"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7005aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fortsett her"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589da73f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "[*back to top*](#top) \n",
    "## <a id=\"1st-iteration\"></a>2) Modelling: Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe57ad",
   "metadata": {},
   "source": [
    "This section will consist of testing, experimenting and implementing different models and further evalute the results. This includes but is not limited to different regression models for accurate predictions of the RMSE for our data. \n",
    "\n",
    "I will also implement and evaluate three different models part the baseline, which hopefully will generate preferred results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a00c4f",
   "metadata": {},
   "source": [
    "### <a id=\"scaling\"></a>2.1) Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50100711",
   "metadata": {},
   "source": [
    "We want to scale our data in a manner such that it is easier to compare them. I've decided to scale the data together as a unit as it is easier to work with the data afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90f9f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling with StandardScaler\n",
    "standardscaler = StandardScaler()\n",
    "\n",
    "# Fit on X_train, transform X_val and X_test\n",
    "X_train_scaled = standardscaler.fit_transform(X_train)\n",
    "X_val_scaled = standardscaler.transform(X_val)\n",
    "X_test_scaled = standardscaler.transform(X_test)\n",
    "X_trainval_scaled = standardscaler.transform(X_trainval)\n",
    "\n",
    "# Fit on y_train, transform y_val and y_test\n",
    "y_train_scaled = standardscaler.fit_transform(y_train)\n",
    "y_val_scaled = standardscaler.transform(y_val)\n",
    "y_test_scaled = standardscaler.transform(y_test)\n",
    "y_trainval_scaled = standardscaler.fit_transform(y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "483c46c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44825, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "024e90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 3 principal components for independent variables (X)\n",
    "pca = PCA(n_components=3)\n",
    "X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "X_val_scaled = pca.transform(X_val_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n",
    "X_trainval_scaled = pca.fit_transform(X_trainval_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129dbf0",
   "metadata": {},
   "source": [
    "The baseline model is the initial value that is using a simple regression model to give an estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64e4cfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_baseline:  71.35\n"
     ]
    }
   ],
   "source": [
    "# Creating the baseline model to estimate number of cyclists per hour\n",
    "# The scaled data will not be used in this particular prediction\n",
    "baseline = DummyRegressor(strategy=\"mean\")\n",
    "baseline.fit(X_train, y_train)\n",
    "baseline_prediction = baseline.predict(X_val_scaled)\n",
    "\n",
    "print('RMSE_baseline: ', np.round(np.sqrt(mean_squared_error(y_val, baseline_prediction)), decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ccc6a0",
   "metadata": {},
   "source": [
    "As we can deduce from the results above, the RMSE baseline is 71.53. Now it's time to compare this to other results with different models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de4426",
   "metadata": {},
   "source": [
    "### <a id=\"linear_regression\"></a>2.2) Linear Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa373612",
   "metadata": {},
   "source": [
    "Now it's time to induce some multi-output regression models. This is because we have two variables in play; X (weather conditions) and y (volume of bicycles). The MultiOutputRegressor function from sklearn is a valuable asset here as it can be used to chain the different models together. Here we assume that the predictor variables are not dependent on each other. This is because ------- ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b013a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "    Predicting with Linear Regression:\n",
      "R2 for predictions made on training data: 0.1959997886183209\n",
      "R2 for predictions made on validation data: 0.1959997886183209\n",
      "RMSE for Linear Regression:  63.98110180123987\n",
      "--------------------------------------------------------------------------\n",
      "    Predicting with Lasso:\n",
      "R2 for predictions made on training data: 0.0\n",
      "R2 for predictions made on validation data: 0.0\n",
      "RMSE for Lasso:  71.35487229550104\n",
      "--------------------------------------------------------------------------\n",
      "    Predicting with Ridge:\n",
      "R2 for predictions made on training data: 0.1959997885541528\n",
      "R2 for predictions made on validation data: 0.1959997885541528\n",
      "RMSE for Ridge:  63.98110180379308\n",
      "--------------------------------------------------------------------------\n",
      "    Predicting with ElasticNet:\n",
      "R2 for predictions made on training data: 0.0\n",
      "R2 for predictions made on validation data: 0.0\n",
      "RMSE for ElasticNet:  71.35487229550104\n"
     ]
    }
   ],
   "source": [
    "linreg_model = LinearRegression()\n",
    "ridge_model = Ridge()\n",
    "lasso_model = Lasso()\n",
    "elasticnet_model = ElasticNet(max_iter=4000)\n",
    "\n",
    "models = [linreg_model, lasso_model, ridge_model, elasticnet_model]\n",
    "\n",
    "\n",
    "# Following code-snippet is from stackOverflow with smaller changes to fit models used\n",
    "for model, modelname in zip(models, [\"Linear Regression\", \"Lasso\", \"Ridge\", \"ElasticNet\"]):\n",
    "    # Training the model \n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    \n",
    "    print(f\"\"\"--------------------------------------------------------------------------\n",
    "    Predicting with {modelname}:\"\"\")\n",
    "    # Prediction on training data\n",
    "    train_predict = model.predict(X_train_scaled)\n",
    "    r2_trainpred = r2_score(y_train_scaled, train_predict)\n",
    "    print(f'R2 for predictions made on training data:', r2_trainpred)\n",
    "\n",
    "    # Prediction on validation data\n",
    "    val_predict = model.predict(X_val_scaled)\n",
    "    r2_valpred = r2_score(y_val_scaled, val_predict)\n",
    "    print(f'R2 for predictions made on validation data:', r2_valpred)\n",
    "\n",
    "    # Calculating the RMSE for predictions made on validation data\n",
    "    val_predict_unscaled = standardscaler.inverse_transform(val_predict.reshape(-1,1))\n",
    "    \n",
    "    print(f'RMSE for {modelname}: ', sqrt(mean_squared_error(val_predict_unscaled, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2029b1",
   "metadata": {},
   "source": [
    "Currently it seems like standard linear regression yields the best result among those chosen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e02b597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fortsett her----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8faafe1",
   "metadata": {},
   "source": [
    "### <a id=\"polynomial_model\"></a>2.3) Polynomial model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d10e83f",
   "metadata": {},
   "source": [
    "A polynomial model is useful for data that is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "242f28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Polynomial Model:  63.06\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "val_predict = model.predict(X_val_scaled)\n",
    "\n",
    "# unscaling\n",
    "val_predict_not_scaled = standardscaler.inverse_transform(val_predict.reshape(-1,1))\n",
    "\n",
    "\n",
    "print('RMSE Polynomial Model: ', np.round(np.sqrt(mean_squared_error(y_val, val_predict_not_scaled)),\n",
    "                        decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80df96",
   "metadata": {},
   "source": [
    "The RMSE seems to be stabilizing around the 65-67 area for the models that we have utilized currently. Polynomial regression seems to be the best performer with a slight better performance than the linear regression models. But the results are still remarkably similar. The polynomial model tends to perform the best when there is no linear correlation between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c59b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2867166 ,  0.1293476 ,  0.17144272],\n",
       "       [ 2.72132315, -0.1661039 ,  0.0547452 ],\n",
       "       [ 2.65817268, -0.03681575,  0.10108044],\n",
       "       ...,\n",
       "       [-0.72333837, -0.29002384,  0.35501222],\n",
       "       [-0.87428721, -0.6100438 ,  0.19991563],\n",
       "       [-1.06457949, -1.18357214, -0.06749217]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d4d81",
   "metadata": {},
   "source": [
    "### <a id=\"k_nearest_neighbour\"></a>2.4) K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf8af61",
   "metadata": {},
   "source": [
    "For the K Nearest Neighbours model I will parameter tune my model with an iterative approach:\n",
    "\n",
    "Note: Another solution would be using the sklearn.GridSearchCV() function, but it is not used here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e645c8",
   "metadata": {},
   "source": [
    "## knn_rmse = 100000 # setting the base RMSE to a ridicuolusly high number\n",
    "best_k = None\n",
    "\n",
    "for k in range(5, 16):\n",
    "    \n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "    knn.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    knn_predict = knn.predict(X_val_scaled)\n",
    "\n",
    "    # unscaling\n",
    "    knn_predict_not_scaled = standardscaler.inverse_transform(knn_predict.reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    new_rmse = np.round(np.sqrt(mean_squared_error(y_val, knn_predict_not_scaled)),\n",
    "                        decimals=2)\n",
    "    print(f\"for {k} neighbours the rmse is: {new_rmse}\")\n",
    "    \n",
    "    if new_rmse < knn_rmse:\n",
    "        knn_rmse = new_rmse\n",
    "        best_k = k\n",
    "\n",
    "print(f\"\\nRMSE K nearest neighbour: {knn_rmse} for {best_k} neighbours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab1a4e",
   "metadata": {},
   "source": [
    "From this, we can further deduce that by manually tuning our parameters our most efficient value for k is the lowest provided. But similarly having to few data points could provide false readings. Hence, we set it between 5 and 15 for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208ad28",
   "metadata": {},
   "source": [
    "### <a id=\"decision_tree\"></a>2.5) The Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "549125b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Decision Tree model:  3.52\n"
     ]
    }
   ],
   "source": [
    "dtm = DecisionTreeRegressor(random_state=random_state)\n",
    "\n",
    "dtm.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "dtm_predict = dtm.predict(X_val_scaled)\n",
    "\n",
    "# unscaling\n",
    "dtm_predict_not_scaled = standardscaler.inverse_transform(dtm_predict.reshape(-1,1))\n",
    "\n",
    "print('RMSE Decision Tree model: ', np.round(np.sqrt(mean_squared_error(y_val, dtm_predict_not_scaled)),\n",
    "                        decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5910f2",
   "metadata": {},
   "source": [
    "So here we have an anomaly. Technically the RMSE for the decision tree model outperforms every other model drastically. The datasets used in this model is equal to the ones used in earlier models. But even though the RMSE is remarkably low, this model cannot be used to estimate the number of cyclists. For some reason the data doesn't fit for this model. Hence, it is disregarded in the final analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9ce3d",
   "metadata": {},
   "source": [
    "### <a id=\"mlp\"></a>2.6) The Multi Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
